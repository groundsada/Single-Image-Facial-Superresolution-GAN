{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Single-Image Facial Super-Resolution Using GANs**\n",
        "_________________________________________________\n",
        "#### **CS584 Project: Report**\n",
        "#### **Fall 2022 |  December 2nd, 2022**\n",
        "__________________________________________________________\n",
        "###### **Mohammad Firas Sada**\n",
        "###### **Antoine Courbot**\n",
        "###### **Aleksander Popovic**\n",
        "_______________________________________"
      ],
      "metadata": {
        "id": "kDRwR1VYnlp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "ksp8aKOgoAeE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dZjhjqqlpWz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras import layers, Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "from keras import Model\n",
        "from keras.layers import Conv2D, PReLU,BatchNormalization, Flatten\n",
        "from keras.layers import UpSampling2D, LeakyReLU, Dense, Input, add\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connecting Google Drive**"
      ],
      "metadata": {
        "id": "vLxkRyDToD9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "%cd /content/drive/MyDrive/CS584/proj"
      ],
      "metadata": {
        "id": "6hGgub7Llxvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the architecture**"
      ],
      "metadata": {
        "id": "mqA0mVkjoHCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def res_block(ip):\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(ip)\n",
        "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
        "    res_model = PReLU(shared_axes = [1,2])(res_model)\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
        "    res_model = BatchNormalization(momentum = 0.5)(res_model)    \n",
        "    return add([ip,res_model])"
      ],
      "metadata": {
        "id": "ndmvFh0_lxC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upscale_block(ip):\n",
        "    up_model = Conv2D(256, (3,3), padding=\"same\")(ip)\n",
        "    up_model = UpSampling2D( size = 2 )(up_model)\n",
        "    up_model = PReLU(shared_axes=[1,2])(up_model)\n",
        "    return up_model"
      ],
      "metadata": {
        "id": "qNkkY3-XoKOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_gen(gen_ip, num_res_block):\n",
        "    layers = Conv2D(64, (9,9), padding=\"same\")(gen_ip)\n",
        "    layers = PReLU(shared_axes=[1,2])(layers)\n",
        "    temp = layers\n",
        "    for i in range(num_res_block):\n",
        "        layers = res_block(layers)\n",
        "    layers = Conv2D(64, (3,3), padding=\"same\")(layers)\n",
        "    layers = BatchNormalization(momentum=0.5)(layers)\n",
        "    layers = add([layers,temp])\n",
        "    layers = upscale_block(layers)\n",
        "    layers = upscale_block(layers)\n",
        "    op = Conv2D(3, (9,9), padding=\"same\")(layers)\n",
        "    return Model(inputs=gen_ip, outputs=op)"
      ],
      "metadata": {
        "id": "Nq8MXRh0oOLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_block(ip, filters, strides=1, bn=True):\n",
        "    \n",
        "    disc_model = Conv2D(filters, (3,3), strides = strides, padding=\"same\")(ip)\n",
        "    \n",
        "    if bn:\n",
        "        disc_model = BatchNormalization( momentum=0.8 )(disc_model)\n",
        "    \n",
        "    disc_model = LeakyReLU( alpha=0.2 )(disc_model)\n",
        "    \n",
        "    return disc_model"
      ],
      "metadata": {
        "id": "59U9KYHVl2DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_disc(disc_ip):\n",
        "    df = 64\n",
        "    d1 = discriminator_block(disc_ip, df, bn=False)\n",
        "    d2 = discriminator_block(d1, df, strides=2)\n",
        "    d3 = discriminator_block(d2, df*2)\n",
        "    d4 = discriminator_block(d3, df*2, strides=2)\n",
        "    d5 = discriminator_block(d4, df*4)\n",
        "    d6 = discriminator_block(d5, df*4, strides=2)\n",
        "    d7 = discriminator_block(d6, df*8)\n",
        "    d8 = discriminator_block(d7, df*8, strides=2)\n",
        "    d8_5 = Flatten()(d8)\n",
        "    d9 = Dense(df*16)(d8_5)\n",
        "    d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "    validity = Dense(1, activation='sigmoid')(d10)\n",
        "    return Model(disc_ip, validity)"
      ],
      "metadata": {
        "id": "RoNSartroXln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "def build_vgg(hr_shape):\n",
        "    vgg = VGG19(weights=\"imagenet\",include_top=False, input_shape=hr_shape)\n",
        "    return Model(inputs=vgg.inputs, outputs=vgg.layers[10].output)\n",
        "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n",
        "    gen_img = gen_model(lr_ip)\n",
        "    \n",
        "    gen_features = vgg(gen_img)\n",
        "    \n",
        "    disc_model.trainable = False\n",
        "    validity = disc_model(gen_img)\n",
        "    \n",
        "    return Model(inputs=[lr_ip, hr_ip], outputs=[validity, gen_features])"
      ],
      "metadata": {
        "id": "2xYeaVq-l6Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=5000\n",
        "lr_list = os.listdir(\"data/lr_images\")[:n]\n",
        "\n",
        "lr_images = []\n",
        "for img in lr_list:\n",
        "    img_lr = cv2.imread(\"data/lr_images/\" + img)\n",
        "    img_lr = cv2.cvtColor(img_lr, cv2.COLOR_BGR2RGB)\n",
        "    lr_images.append(img_lr)   \n",
        "\n",
        "\n",
        "hr_list = os.listdir(\"data/hr_images\")[:n]\n",
        "   \n",
        "hr_images = []\n",
        "for img in hr_list:\n",
        "    img_hr = cv2.imread(\"data/hr_images/\" + img)\n",
        "    img_hr = cv2.cvtColor(img_hr, cv2.COLOR_BGR2RGB)\n",
        "    hr_images.append(img_hr)   \n",
        "\n",
        "lr_images = np.array(lr_images)\n",
        "hr_images = np.array(hr_images)"
      ],
      "metadata": {
        "id": "JURNkSNvl-3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(lr_images)-1)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.reshape(lr_images[image_number], (32, 32, 3)))\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(hr_images[image_number], (128, 128, 3)))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jLcsGQStmwIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_images = lr_images / 255.\n",
        "hr_images = hr_images / 255."
      ],
      "metadata": {
        "id": "yVL6ZA3HmyYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_train, lr_test, hr_train, hr_test = train_test_split(lr_images, hr_images, \n",
        "                                                      test_size=0.33, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "hr_shape = (hr_train.shape[1], hr_train.shape[2], hr_train.shape[3])\n",
        "lr_shape = (lr_train.shape[1], lr_train.shape[2], lr_train.shape[3])\n",
        "\n",
        "lr_ip = Input(shape=lr_shape)\n",
        "hr_ip = Input(shape=hr_shape)\n"
      ],
      "metadata": {
        "id": "GAwlV8iwm0AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = create_gen(lr_ip, num_res_block = 16)\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "gqII4nvym2G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = create_disc(hr_ip)\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "9Yh06PULm3eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = build_vgg((128,128,3))\n",
        "print(vgg.summary())\n",
        "vgg.trainable = False"
      ],
      "metadata": {
        "id": "riCCXcy7m4zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan_model = create_comb(generator, discriminator, vgg, lr_ip, hr_ip)"
      ],
      "metadata": {
        "id": "rvbW-ie6m6sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan_model.compile(loss=[\"binary_crossentropy\", \"mse\"], loss_weights=[1e-3, 1], optimizer=\"adam\")\n",
        "gan_model.summary()"
      ],
      "metadata": {
        "id": "nE9zLtF0m-wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1  \n",
        "train_lr_batches = []\n",
        "train_hr_batches = []\n",
        "for it in range(int(hr_train.shape[0] / batch_size)):\n",
        "    start_idx = it * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    train_hr_batches.append(hr_train[start_idx:end_idx])\n",
        "    train_lr_batches.append(lr_train[start_idx:end_idx])"
      ],
      "metadata": {
        "id": "2C7SXcpnnAix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    \n",
        "    fake_label = np.zeros((batch_size, 1)) # Assign a label of 0 to all fake (generated images)\n",
        "    real_label = np.ones((batch_size,1)) # Assign a label of 1 to all real images.\n",
        "    \n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "    \n",
        "    for b in tqdm(range(len(train_hr_batches))):\n",
        "        lr_imgs = train_lr_batches[b] #Fetch a batch of LR images for training\n",
        "        hr_imgs = train_hr_batches[b] #Fetch a batch of HR images for training\n",
        "        \n",
        "        fake_imgs = generator.predict_on_batch(lr_imgs) #Fake images\n",
        "        \n",
        "        discriminator.trainable = True\n",
        "        d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n",
        "        d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n",
        "\n",
        "\n",
        "        discriminator.trainable = False\n",
        "        \n",
        "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real) \n",
        "        \n",
        "        image_features = vgg.predict(hr_imgs)\n",
        "     \n",
        "        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, image_features])\n",
        "        \n",
        "        d_losses.append(d_loss)\n",
        "        g_losses.append(g_loss)\n",
        "        \n",
        "    g_losses = np.array(g_losses)\n",
        "    d_losses = np.array(d_losses)\n",
        "    \n",
        "    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
        "    d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
        "    \n",
        "    print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
        "\n",
        "    if (e+1) % 10 == 0: #Change the frequency for model saving, if needed\n",
        "        generator.save(\"gen_e_\"+ str(e+1) +\".h5\")\n"
      ],
      "metadata": {
        "id": "y9Q3ORbRnCd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from numpy.random import randint\n",
        "\n",
        "generator = load_model('gen_e_10.h5', compile=False)\n",
        "\n",
        "\n",
        "[X1, X2] = [lr_test, hr_test]\n",
        "\n",
        "ix = randint(0, len(X1), 1)\n",
        "src_image, tar_image = X1[ix], X2[ix]\n",
        "\n",
        "gen_image = generator.predict(src_image)"
      ],
      "metadata": {
        "id": "DoovbBcenE9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('LR Image')\n",
        "plt.imshow(src_image[0,:,:,:])\n",
        "plt.subplot(232)\n",
        "plt.title('Superresolution')\n",
        "plt.imshow(gen_image[0,:,:,:])\n",
        "plt.subplot(233)\n",
        "plt.title('Orig. HR image')\n",
        "plt.imshow(tar_image[0,:,:,:])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8ssokaw1nH4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sreeni_lr = cv2.imread(\"data/sreeni_32.jpg\")\n",
        "sreeni_hr = cv2.imread(\"data/sreeni_256.jpg\")\n",
        "\n",
        "sreeni_lr = cv2.cvtColor(sreeni_lr, cv2.COLOR_BGR2RGB)\n",
        "sreeni_hr = cv2.cvtColor(sreeni_hr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "sreeni_lr = sreeni_lr / 255.\n",
        "sreeni_hr = sreeni_hr / 255.\n",
        "\n",
        "sreeni_lr = np.expand_dims(sreeni_lr, axis=0)\n",
        "sreeni_hr = np.expand_dims(sreeni_hr, axis=0)\n",
        "\n",
        "generated_sreeni_hr = generator.predict(sreeni_lr)"
      ],
      "metadata": {
        "id": "v2NqY-KenJrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('LR Image')\n",
        "plt.imshow(sreeni_lr[0,:,:,:])\n",
        "plt.subplot(232)\n",
        "plt.title('Superresolution')\n",
        "plt.imshow(generated_sreeni_hr[0,:,:,:])\n",
        "plt.subplot(233)\n",
        "plt.title('Orig. HR image')\n",
        "plt.imshow(sreeni_hr[0,:,:,:])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9VrXnfP2nNNT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}